using ArgParse

argSettings = ArgParseSettings(description = string(
"This is a tool for systematically generating LSF jobs which write to log files. Below is an outline of the process.\n",
"\n",
"\n",
"\n",
"\n",
"\n  STAGE 1: Generate summary files for each set of input data.\n",
"\n",
"\n",
"\n    STAGE 1 INPUTS:\n",
"\nPath to protocol file (-p).\n",
"\n(Optional) Variables file supplied with the --vars (-r) option.\n",
"\n(Optional) Variables from lists file supplied with the --fvars (-f) option.\n",
"\n",
"\n",
"\n    STAGE 1 OUTPUTS:\n",
"\nSummary files generated by expanding the variables in the protocol file.\n",
"\nText file listing paths to the generated summary files.\n",
"\n",
"\n",
"\n",
"\n",
"\n   STAGE 2: Generate job files.\n",
"\n",
"\n",
"\n     STAGE 2 INPUTS:\n",
"\nText file listing the of paths to the generated summary files.  If stages 1 and 2 are run together the summary files from stage 1 will be used.\n",
"\n",
"\n",
"\n     STAGE 2 OUTPUTS:\n",
"\nJob files generated from summary files.\n",
"\nText file listing paths to the generated job files.\n",
"\n",
"\n",
"\n",
"\n",
"\n   STAGE 3: Submit jobs to the queuing system.\n",
"\n",
"\n",
"\n     STAGE 3 INPUTS:\n",
"\nText file listing paths to the generated job files.  If stages 2 and 3 are run together the job files from stage 2 will be used for stage 3.\n",
"\n",
"\n",
"\n     STAGE 3 OUTPUTS:\n",
"\nLog files written by the job files.\n",
"\nStarndard output and error output from the queuing system as well as any output produced by running the commands contained in the job files.",
"\n",
"\n",
"\n",
));
sourcePath = dirname(Base.source_path()) * "/"; # Get the path to the jsub.jl file

####### INPUTS #######

# Variables file
# fileVars="/Users/olenive/work/jsub_pipeliner/unit_tests/protocols/sample_variables/call_bash_scripts_pathVar_sampleVars.vars";

# Variables from list
#fileFvars="/Users/olenive/work/jsub_pipeliner/unit_tests/protocols/sample_variables/call_bash_scripts_pathVar_sampleVars.fvars"
# fileFvars="/Users/olenive/work/jsub_pipeliner/unit_tests/protocols/split/refs_samples.fvars";

# summaryFilePrefix="TEST/summaries/";
jobFilePrefix = sourcePath * "TEST/jobfiles/";

## Default job header values
# jobID="LSFjob";
# numberOfCores=1;
# numberOfHosts=1;
# wallTime="8:00";
# queue="normal"
# grantCode="prepay-houlston"

# String added to the header of every job file
commonHeaderSuffix = "\n#BSUB -P prepay-houlston";

# jobHeader = string(
# "#!/bin/bash\n
# #BSUB -J \"$jobID\"\n
# #BSUB -n $numberOfCores\n
# #BSUB -R \"span[hosts=$numberOfHosts]\"\n
# #BSUB -P $grantCode\n
# #BSUB -W $wallTime\n
# #BSUB -q $queue\n
# #BSUB -o output.$jobID\n
# #BSUB -e error.$jobID\n"
# )

######################

## Hard coded variables
# First non-whitespace string indicating the start of a comment line
const comStr="#" # Note: this is expected to be a string ("#") rather than a character ('#').  Changing the string (char) used to indicate comments may cause problems further down the line.
# const dlmVars='\t' # Column delimiter for files containing variables
# const dlmProtocol=' ' # Column delimiter for the protocol file
const dlmWhitespace=[' ','\t','\n','\v','\f','\r'] # The default whitespace characters used by split
const delimiterFvars = '\t'
const verbose = false;
const adapt_quotation=true; # this should be the default to avoid nasty accidents

num_suppressed = [0];

## Tags
tagsExpand = Dict(
  "header" => "#BSUB",
  "tagSummaryName" => "#JSUB<summary-name>",
  "tagSplit" => "#JGROUP"
)

## Paths to bash functions {"function name" => "path to file containing function"}
commonFunctions = Dict(
  "kill_this_job" => sourcePath * "common_functions/job_processing.sh",
  "process_job" => sourcePath * "common_functions/job_processing.sh",
)
checkpointsDict = Dict()

#### FUNCTIONS ####
include("./common_functions/jsub_common.jl")
###################

######### MAIN #########
# function main(args)
## Argparse settings
@add_arg_table argSettings begin
  "-p", "--protocol"
    help = "Path to \"protocol\" file.  This file contains commands to be run with variables to be substituted using values from files supplied with \"--vars (-r)\" and/or \"--fvars (-f)\" options."

  "-v", "--verbose"
    action = :store_true
    help = "Verbose mode prints warnings and additional information to std out." 

  "-s", "--generate-summaries"
    action = :store_true
    help = "Generate summary files from protocol files using variables from files where supplied (see --help for --vars & --fvars options)." 

  "-j", "--generate-jobs"
    action = :store_true
    help = "Generate LSF job files from summary files." 

  "-u", "--list-summaries"
    help = "Path to a text file listing summary file paths." 

  "-o", "--list-jobs"
    help = "Path to a text file listing job file paths." 

  "-b", "--submit-jobs"
    action = :store_true
    help = "Submit LSF job files to the queue." 

  "-r", "--vars"
    help = "Path to \"variables\" file.  This file contains two columns - variable names and variable values.  Matching variable names found in the \"protocol\" will be substituted with the corresponding values.  Variable names may themselves contain variables which will be expanded if the variable name-value pair is found above (in this vars file)."

  "-f", "--fvars"
    help = "Path to \"file variables\" file.  The purpose of this file is to declare variables that are to be substituted with values taken from a list in another file.  This file consists of three columns - variable names, list file column and list file path."

  "-w", "--suppress-warnings"
    action = :store_true
    help = "Do not print warnings to std out." 

  "-m", "--summary-prefix"
    help = "Prefix to summary files."

  "-q", "--job-prefix"
    help = "Prefix to job files."

  "-t", "--timestamp"
    action = :store_true
    help = "Add timestamps to summary files."

  "-a", "--portable"
    action = :store_true
    help = "Write a copy of the submission script and relevant functions to the directory containing the job files so that it may be copied over to and run on a system that does not have a working copy of jsub.jl."

  "-z", "--zip-jobs"
    action = :store_true
    help = "Create a zip file containing the jobs directory for ease of copying."
end

parsed_args = parse_args(argSettings) # the result is a Dict{String,Any}
println("Parsed args:")
for (key,val) in parsed_args
    println("  $key  =>  $(repr(val))")
end

## Process flag states
SUPPRESS_WARNINGS = parsed_args["suppress-warnings"];
flagVerbose = parsed_args["verbose"];
requiredStages = map_flags_sjb(parsed_args["generate-summaries"], parsed_args["generate-jobs"], parsed_args["submit-jobs"])
println(requiredStages);

## Check for conflicting arguments
if requiredStages[1] == '1' && requiredStages[2] == '1' && parsed_args["list-summaries"] != nothing
  error("Abiguous combination of options (-u): Stages 1 and 2 are being run together but an argument has been passed to the \"--list-summaries\" (-u) option.  This is disallowed to prevent the confusing situation in which job files produced during Stage 2 are unrelated to the summary files produced at Stage 1.  \nTo resolve this, ommit the \"--list-summaries\" (-u) option or run Stages 1 and 2 separately.");
end
if requiredStages[2] == '1' && requiredStages[3] == '1' && parsed_args["list-jobs"] != nothing
  error("Abiguous combination of options (-o): Stages 2 and 3 are being run together but an argument has been passed to the \"--list-jobs\" (-o) option.  This is disallowed to prevent the confusing situation in which job files produced during Stage 2 are not the files being submitted to the queuing system in Stage 3.  \nTo resolve this, ommit the \"--list-jobs\" (-o) option or run Stages 2 and 3 separately.");
end

### TODO: INPUT CHECKS ###
# Check that fileFvars contains 3 delmiterFvars separated columns

## Initialise shared variables

## Get file paths from arguments
fileProtocol = get_argument(parsed_args, "protocol"; verbose=flagVerbose);
fileVars = get_argument(parsed_args, "vars"; verbose=flagVerbose, optional=true, path=true);
fileFvars = get_argument(parsed_args, "fvars"; verbose=flagVerbose, optional=true, path=true);

## Determine string used in file names
longName = get_longname(fileProtocol, fileVars, fileFvars, keepSuffix=false);
flagVerbose && println(string("Prefix for output file base-names: ", longName));

summaryPaths = [];
jobFilePaths = [];
pathJobsList = string(jobFilePrefix, longName, ".jobs-list");
dirJobs = dirname(pathJobsList);
pathSubmissionScript = string(sourcePath, "/common_functions/submit_lsf_jobs.sh");
pathSubmissionFunctions = string(sourcePath, "/common_functions/jobs_submission_functions.sh");
jobFilePrefix = string(sourcePath, parsed_args["job-prefix"]);

# String added to the header of every job file
commonHeaderSuffix = "\n#BSUB -P prepay-houlston";

## STAGE 1
if requiredStages[1] == '1'
  flagVerbose && println("\n - STAGE 1: Generating summary files using data from files supplied to the --protocol, --vars and --fvars options.");

  ## Read protocol, vars and fvars files and expand variables
  namesVars = []; valuesVars = [];
  if parsed_args["vars"] != nothing
    flagVerbose && println(string("Expand variables line by line in data from (--vars) file: ", fileVars));
    # Read .vars file # Extract arrays of variable names and variable values
    namesVarsRaw, valuesVarsRaw = parse_varsfile_(parsed_args["vars"], tagsExpand=tagsExpand);
    # Expand variables in each row from .vars if they were assigned in a higher row (as though they are being assigned at the command line).
    namesVars, valuesVars = expandinorder(namesVarsRaw, valuesVarsRaw, adapt_quotation=adapt_quotation);
  end
  namesFvars = []; infileColumnsFvars = []; filePathsFvars = [];
  if parsed_args["fvars"] != nothing
    flagVerbose && println(string("Expand variables in data from (--fvars) file: ", fileFvars));
    # Read .fvar file (of 3 columns) and expand variables from .vars
    namesFvars, infileColumnsFvars, filePathsFvars = parse_expandvars_fvarsfile_(fileFvars, namesVars, valuesVars; dlmFvars=delimiterFvars, adapt_quotation=adapt_quotation, tagsExpand=tagsExpand);
  end

  # Read .protocol file (of 1 column ) and expand variables from .vars
  (flagVerbose && length(namesVars) > 0) && println("Expanding variables in protocol file using values from the --vars file.");
  arrProtExpVars, cmdRowsProt = parse_expandvars_protocol_(fileProtocol, namesVars, valuesVars, adapt_quotation=adapt_quotation);

  dictListArr = Dict(); dictCmdLineIdxs = Dict();
  if parsed_args["fvars"] != nothing
    println(string("Expanding variables from the --fvars file using values from the files listed in each row..."));
    dictListArr, dictCmdLineIdxs = parse_expandvars_listfiles_(filePathsFvars, namesVars, valuesVars, delimiterFvars; verbose=false, adapt_quotation=adapt_quotation, tagsExpand=tagsExpand);
    if length(keys(dictListArr)) != length(keys(dictCmdLineIdxs))
      error("Numbers of command rows (", length(keys(dictListArr)), ") and command row indices (", length(keys(dictCmdLineIdxs)), ") in list file (", filePathsFvars, ") do not match.")
    end
  end

  ## Create summary files
  # Use variable values from "list" files to create multiple summary file arrays from the single .protocol file array
  flagVerbose && println("Creating summary files...");
  arrArrExpFvars = [];
  if length(keys(dictListArr)) != 0 && length(keys(dictCmdLineIdxs)) != 0
    arrArrExpFvars = protocol_to_array(arrProtExpVars, cmdRowsProt, namesFvars, infileColumnsFvars, filePathsFvars, dictListArr, dictCmdLineIdxs; verbose=verbose, adapt_quotation=adapt_quotation);
  else
    push!(arrArrExpFvars, arrProtExpVars); # If there is no data from list files, simply proceed using the protocol with expanded varibles (if applicable)
  end
  # Generate list of summary file paths. 

  summaryPrefix = get_argument(parsed_args, "summary-prefix"; verbose=flagVerbose, optional=true, path=true);

  summaryPaths = get_summary_names(arrArrExpFvars; tag="#JSUB<summary-name>", # if an entry with this tag is found in the protocol (arrArrExpFvars), the string following the tag will be used as the name
    longName=longName, # Otherwise the string passed to longName will be used as the basis of the summary file name
    prefix=summaryPrefix,
    suffix=".summary",
    timestamp=(
      parsed_args["timestamp"] ? get_timestamp_(nothing) : "";
    )
  );
  # Take an expanded protocol in the form of an array of arrays and produce a summary file for each entry
  outputSummaryPaths = create_summary_files_(arrArrExpFvars, summaryPaths; verbose=flagVerbose);
  pathSummaryList = string(summaryPrefix, longName, ".summaries-list");
  println(string("Writing list of summary files to: ", pathSummaryList));
  writedlm(pathSummaryList, outputSummaryPaths);
  flagVerbose && println("");
end

## STAGE 2
if requiredStages[2] == '1'
  flagVerbose && println(" - STAGE 2: Using summary files to generate LSF job files.");
  
  ## If stage 1 was run use the list of summary files from it.  Otherwise, read paths to summary files from a file given in command line arguments.
  summaryPaths2 = [];
  if requiredStages[1] == '1'
    summaryPaths2 = summaryPaths;
    flagVerbose && println(string("Using summary files generated during \"STAGE 1\"."));
    if parsed_args["list-summaries"] != nothing
      error("Abiguous options: Stages 1 and 2 are being run together but an argument has been passed to the \"--list-summaries\" (-u) option.  This is disallowed to prevent the confusing situation in which summary files produced during Stage 2 are unrelated to the input data passed in at Stage 1.  \nTo resolve this, ommit the \"--list-summaries\" (-u) option or run Stages 1 and 2 separately.");
    end
  else
    fileSummaryPaths = get_argument(parsed_args, "list-summaries"; verbose=flagVerbose, optional=false, path=true);
    flagVerbose && println(string("Reading list of summary file paths from: ", fileSummaryPaths));
    summaryPaths2 = readdlm(fileSummaryPaths);
  end

  # Note: file2arrayofarrays_ returns a tuple of file contents (in an array) and line number indices (in an array)
  summaryFilesData = map((x) -> file2arrayofarrays_(x, "#", cols=1, tagsExpand=tagsExpand), summaryPaths2 );

  flagVerbose && println("Importing bash functions from files...");
  arrDictCheckpoints = map((x) -> identify_checkpoints(x[1], checkpointsDict; tagCheckpoint="jcheck_"), summaryFilesData );
  arrBashFunctions = map((x) -> get_bash_functions(commonFunctions, x), arrDictCheckpoints);

  flagVerbose && println("Splitting summary file contents into separate jobs...");
  summaryArrDicts = map((x) -> split_summary(x[1]; tagSplit=tagsExpand["tagSplit"]), summaryFilesData);

  flagVerbose && println("Getting job file names from summary file basenames...");
  arrJobIDs = map((x) -> basename(remove_suffix(x, ".summary")) , summaryPaths2);

  ## Write job files
  jobFilePaths = map((summaryFilePath, dictSummaries, jobID) -> create_jobs_from_summary_(summaryFilePath, dictSummaries, commonFunctions, checkpointsDict; 
    jobFilePrefix=jobFilePrefix, jobID=jobID, jobDate=get_timestamp_(nothing), headerSuffix=commonHeaderSuffix, verbose=flagVerbose),
    summaryPaths2, summaryArrDicts, arrJobIDs
  );
  
  println(string("Writing list of job files to: ", pathJobsList));
  writedlm(pathJobsList, jobFilePaths);

  flagVerbose && println("");
end

## STAGE 3
if requiredStages[3] == '1'
  flagVerbose && println(" - STAGE 3: Submitting LSF jobs.");

  ## If Stage 2 was run, use the list of job files generated from it.  Otherwise, read paths to job files from a file given in the command line arguments.
  jobFilePaths2 = [];
  if requiredStages[2] == '1'
    jobFilePaths2 = jobFilePaths;
    flagVerbose && println(string("Using job files generated during \"STAGE 2\"."));
    if parsed_args["list-jobs"] != nothing
      error("Abiguous combination of options (-o): Stages 2 and 3 are being run together but an argument has been passed to the \"--list-jobs\" (-o) option.  This is disallowed to prevent the confusing situation in which job files produced during Stage 2 are not the files being submitted to the queuing system in Stage 3.  \nTo resolve this, ommit the \"--list-jobs\" (-o) option or run Stages 2 and 3 separately.");
    end
  else
    fileJobPaths = get_argument(parsed_args, "list-jobs"; verbose=flagVerbose, optional=false, path=true);
    flagVerbose && println(string("Reading list of summary file paths from: ", fileJobPaths));
    jobFilePaths2 = readdlm(fileJobPaths);
  end

  ## Call the job submission script (or generate a portable script?)
  if parsed_args["portable"] == false
    SUPPRESS_WARNINGS ? arg2 = "suppress-warnings" : arg2 = "pass";
    submitCommand = string("bash ", sourcePath, "/common_functions/submit_lsf_jobs.sh ", fileJobPaths, " ", arg2,);
    flagVerbose && println("Submitting jobs to LSF queuing system using command:");
    flagVerbose && println(submitCommand);
    run(submitCommand);
  else
    flagVerbose && println(string("Writing a copy of the submission script and functions file to the job file directory: ", dirJobs));
    cp()
    flagVerbose && println(string("The jobs can be submitted to the queuing system by running the shell script, for example: ", ));
  end

  ## Zip jobs directory if requested
  if parsed_args["zip-jobs"] == true
    flagVerbose && println("Zipping jobs directory: ", dirJobs);
    flagVerbose ? zipVerbose = " -v " : zipVerbose = ""
    cmdZip = string("tar -z -c -f ", zipVerbose, " ", dirJobs, ".tar.gz ", dirJobs );
    run(cmdZip)
  end

  flagVerbose && println("");
end

# end
# main(ARGS)

# Report if there were any suppressed warnings
if num_suppressed[1] > 0
  println("Suppressed ", num_suppressed[1], " warnings.");
end
########################
# EOF

