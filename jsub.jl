using ArgParse

argSettings = ArgParseSettings(description = string(
"This is a tool for systematically generating LSF jobs which write to log files. Below is an outline of the process.\n",
"\n",
"\n",
"\n",
"\n",
"\n  STAGE 1: Generate summary files for each set of input data.\n",
"\n",
"\n",
"\n    STAGE 1 INPUTS:\n",
"\nPath to protocol file (-p).\n",
"\n(Optional) Variables file supplied with the --vars (-r) option.\n",
"\n(Optional) Variables from lists file supplied with the --fvars (-f) option.\n",
"\n",
"\n",
"\n    STAGE 1 OUTPUTS:\n",
"\nSummary files generated by expanding the variables in the protocol file.\n",
"\nText file listing paths to the generated summary files.\n",
"\n",
"\n",
"\n",
"\n",
"\n   STAGE 2: Generate job files.\n",
"\n",
"\n",
"\n     STAGE 2 INPUTS:\n",
"\nText file listing the of paths to the generated summary files.  If stages 1 and 2 are run together the summary files from stage 1 will be used.\n",
"\n",
"\n",
"\n     STAGE 2 OUTPUTS:\n",
"\nJob files generated from summary files.\n",
"\nText file listing paths to the generated job files.\n",
"\n",
"\n",
"\n",
"\n",
"\n   STAGE 3: Submit jobs to the queuing system.\n",
"\n",
"\n",
"\n     STAGE 3 INPUTS:\n",
"\nText file listing paths to the generated job files.  If stages 2 and 3 are run together the job files from stage 2 will be used for stage 3.\n",
"\n",
"\n",
"\n     STAGE 3 OUTPUTS:\n",
"\nLog files written by the job files.\n",
"\nStarndard output and error output from the queuing system as well as any output produced by running the commands contained in the job files.",
"\n",
"\n",
"\n",
));
sourcePath = dirname(Base.source_path()) * "/"; # Get the path to the jsub.jl file

####### INPUTS #######

## Default job header values
# jobID="LSFjob";
# numberOfCores=1;
# numberOfHosts=1;
# wallTime="8:00";
# queue="normal"
# grantCode="prepay-houlston"

# jobHeader = string(
# "#!/bin/bash\n
# #BSUB -J \"$jobID\"\n
# #BSUB -n $numberOfCores\n
# #BSUB -R \"span[hosts=$numberOfHosts]\"\n
# #BSUB -P $grantCode\n
# #BSUB -W $wallTime\n
# #BSUB -q $queue\n
# #BSUB -o output.$jobID\n
# #BSUB -e error.$jobID\n"
# )

######################

## Hard coded variables
# First non-whitespace string indicating the start of a comment line
const comStr="#" # Note: this is expected to be a string ("#") rather than a character ('#').  Changing the string (char) used to indicate comments may cause problems further down the line.
# const dlmVars='\t' # Column delimiter for files containing variables
# const dlmProtocol=' ' # Column delimiter for the protocol file
const dlmWhitespace=[' ','\t','\n','\v','\f','\r'] # The default whitespace characters used by split
const delimiterFvars = '\t'
const verbose = false;
const adapt_quotation=true; # this should be the default to avoid nasty accidents

num_suppressed = [0];

## Tags
tagsExpand = Dict(
  "header" => "#BSUB",
  "tagSummaryName" => "#JSUB<summary-name>",
  "tagSplit" => "#JGROUP"
)

## Paths to bash functions {"function name" => "path to file containing function"}
commonFunctions = Dict(
  "kill_this_job" => sourcePath * "common_functions/job_processing.sh",
  "process_job" => sourcePath * "common_functions/job_processing.sh",
  "version_control" => sourcePath * "common_functions/version_control.sh",
)
checkpointsDict = Dict()

bsubOptions = [
"-ar",
"-B",
"-H",
"-I", "-Ip", "-Is", # [-tty]
"-IS", "-ISp", "-ISs", "-IX", #[-tty]
"-K",
"-N",
"-r", "-rn",
"-ul",
"-a", "esub_application", # [([argument[,argument...]])]..."
"-app", # application_profile_name
"-b", # [[year:][month:]day:]hour:minute
"-C", # core_limit
"-c", # [hour:]minute[/host_name | /host_model]
"-clusters", # "all [~cluster_name] ... | cluster_name[+[pref_level]] ... [others[+[pref_level]]]"
"-cwd", # "current_working_directory"
"-D", # data_limit
"-E", # "pre_exec_command [arguments ...]"
"-Ep", # "post_exec_command [arguments ...]"
"-e", # error_file
"-eo", #error_file
"-ext", #[sched] "external_scheduler_options"
"-F", # file_limit
"-f", # local_file operator [remote_file]" ...
"-freq", # numberUnit
"-G", # user_group
"-g", # job_group_name
"-i", # input_file | -is input_file
"-J", # job_name | -J "job_name[index_list]%job_slot_limit"
"-Jd", # "job_description"
"-jsdl", # file_name | -jsdl_strict file_name
"-k", # "checkpoint_dir [init=initial_checkpoint_period][checkpoint_period] [method=method_name]"
"-L", # login_shell
"-Lp", # ls_project_name
"-M", # mem_limit
"-m", # "host_name[@cluster_name][[!] | +[pref_level]] | host_group[[!] | +[pref_level | compute_unit[[!] | +[pref_level]] ..."
"-mig", # migration_threshold
"-n", # min_proc[,max_proc]
"-network", # " network_res_req"
"-o", # output_file
"-oo", # output_file
"-outdir", # output_directory
"-P", # project_name
"-p", # process_limit
"-pack", # job_submission_file
"-Q", # "[exit_code ...] [EXCLUDE(exit_code ...)]"
"-q", # "queue_name ..."
"-R", # "res_req" [-R "res_req" ...]
"-rnc", # resize_notification_cmd
"-S", # stack_limit
"-s", # signal
"-sla", # service_class_name
"-sp", # priority
"-T", # thread_limit
"-t", # [[[year:]month:]day:]hour:minute
"-U", # reservation_ID
"-u", # mail_user
"-v", # swap_limit
"-W", # [hour:]minute[/host_name | /host_model]
"-We", # [hour:]minute[/host_name | /host_model]
"-w", # 'dependency_expression'
"-wa", # 'signal'
"-wt", # '[hour:]minute'
"-XF",
"-Zs",
"-h",
"-V",
];

#### FUNCTIONS ####
include("./common_functions/jsub_common.jl")
###################

######### MAIN #########
# function main(args)
## Argparse settings
@add_arg_table argSettings begin
  "-p", "--protocol"
    help = "Path to \"protocol\" file.  This file contains commands to be run with variables to be substituted using values from files supplied with \"--vars (-r)\" and/or \"--fvars (-f)\" options."

  "-v", "--verbose"
    action = :store_true
    help = "Verbose mode prints warnings and additional information to std out." 

  "-s", "--generate-summaries"
    action = :store_true
    help = "Generate summary files from protocol files using variables from files where supplied (see --help for --vars & --fvars options)." 

  "-j", "--generate-jobs"
    action = :store_true
    help = "Generate LSF job files from summary files." 

  "-u", "--list-summaries"
    help = "Path to a text file listing summary file paths." 

  "-o", "--list-jobs"
    help = "Path to a text file listing job file paths." 

  "-b", "--submit-jobs"
    action = :store_true
    help = "Submit LSF job files to the queue." 

  "-r", "--vars"
    help = "Path to \"variables\" file.  This file contains two columns - variable names and variable values.  Matching variable names found in the \"protocol\" will be substituted with the corresponding values.  Variable names may themselves contain variables which will be expanded if the variable name-value pair is found above (in this vars file)."

  "-f", "--fvars"
    help = "Path to \"file variables\" file.  The purpose of this file is to declare variables that are to be substituted with values taken from a list in another file.  This file consists of three columns - variable names, list file column and list file path."

  "-w", "--suppress-warnings"
    action = :store_true
    help = "Do not print warnings to std out." 

  "-m", "--summary-prefix"
    help = "Prefix to summary files."

  "-n", "--name"
    help = "Name string to be used in all files."

  "-q", "--job-prefix"
    help = "Prefix to job files."

  "-t", "--timestamp"
    action = :store_true
    help = "Add timestamps to summary files."

  "-a", "--portable"
    action = :store_true
    help = "Write a copy of the submission script and relevant functions to the directory containing the job files so that it may be copied over to and run on a system that does not have a working copy of jsub.jl."

  "-z", "--zip-jobs"
    action = :store_true
    help = "Create a zip file containing the jobs directory for ease of copying."

  "-c", "--common-header"
    help = "String to be included in every job file header."

  "-y", "--no-version-control"
    action = :store_false
    help = "Do not call the bash function which does version control inside these jobs."

  "-d", "--no-process-timestamp"
    action = :store_false
    help = "When this flag is not present, timestamps of the format \"YYYYMMDD_HHMMSS\" are added to the log file by job files running the process_job function."
end

parsed_args = parse_args(argSettings) # the result is a Dict{String,Any}
# for (key,val) in parsed_args
#     println("  $key  =>  $(repr(val))")
# end

## Process flag states
SUPPRESS_WARNINGS = parsed_args["suppress-warnings"];
flagVerbose = parsed_args["verbose"];
requiredStages = map_flags_sjb(parsed_args["generate-summaries"], parsed_args["generate-jobs"], parsed_args["submit-jobs"])
flagVerbose && print("\nInterpreted jsub arguments as requesting the following stages: ")
(flagVerbose && requiredStages[1]=='1') && print("1 ")
(flagVerbose && requiredStages[2]=='1') && print("2 ")
(flagVerbose && requiredStages[3]=='1') && print("3 ")
flagVerbose && print("\n\n")

## Initialise shared variables
summaryPaths = [];
jobFilePaths = [];
pathSubmissionScript = string(sourcePath, "/common_functions/submit_lsf_jobs.sh");
pathSubmissionFunctions = string(sourcePath, "/common_functions/jobs_submission_functions.sh");

## Get file paths and prefixes from arguments
fileProtocol = get_argument(parsed_args, "protocol"; verbose=flagVerbose, optional=(requiredStages[1]=='0'),
  default=""
);
fileVars = get_argument(parsed_args, "vars"; verbose=flagVerbose, optional=true, default="");
fileFvars = get_argument(parsed_args, "fvars"; verbose=flagVerbose, optional=true, default="");
summaryFilePrefix = get_argument(parsed_args, "summary-prefix", verbose=flagVerbose, optional=true, default="");
jobFilePrefix = get_argument(parsed_args, "job-prefix", verbose=flagVerbose, optional=true, default="");

## Determine string used in file names
longName = get_argument(parsed_args, "name"; verbose=flagVerbose, optional=true, 
  default=get_longname(fileProtocol, fileVars, fileFvars,
    get_argument(parsed_args, "list-summaries"; optional=true, default=""),
    get_argument(parsed_args, "list-jobs"; optional=true, default=""),
    keepSuffix=false
  )
);

## Get path to summaries list file
pathSummariesList = get_argument(parsed_args, "list-summaries"; verbose=flagVerbose, optional=true,
 default=string(summaryFilePrefix, longName, ".list-summaries")
);

## Get path to jobs list file
pathJobsList = get_argument(parsed_args, "list-jobs"; verbose=flagVerbose, optional=true,
 default=string(jobFilePrefix, longName, ".list-jobs")
);

# String added to the header of every job file
pathCommonHeader = get_argument(parsed_args, "common-header"; verbose=flagVerbose, optional=true, default=nothing);
pathCommonHeader != nothing ? commonHeaderSuffix = readall(pathCommonHeader) : commonHeaderSuffix="";

flagVerbose && println(string("Prefix for output file names: ", longName));

## TODO: Check input file format
# Check that fileFvars contains 3 delmiterFvars separated columns

## STAGE 1
if requiredStages[1] == '1'
  flagVerbose && println("\n - STAGE 1: Generating summary files using data from files supplied to the --protocol, --vars and --fvars options.");

  ## Read protocol, vars and fvars files and expand variables
  namesVars = []; valuesVars = [];
  if parsed_args["vars"] != nothing
    flagVerbose && println(string("Expand variables line by line in data from (--vars) file: ", fileVars));
    # Read .vars file # Extract arrays of variable names and variable values
    namesVarsRaw, valuesVarsRaw = parse_varsfile_(parsed_args["vars"], tagsExpand=tagsExpand);
    # Expand variables in each row from .vars if they were assigned in a higher row (as though they are being assigned at the command line).
    namesVars, valuesVars = expandinorder(namesVarsRaw, valuesVarsRaw, adapt_quotation=adapt_quotation);
  end
  namesFvars = []; infileColumnsFvars = []; filePathsFvars = [];
  if parsed_args["fvars"] != nothing
    flagVerbose && println(string("Expand variables in data from (--fvars) file: ", fileFvars));
    # Read .fvar file (of 3 columns) and expand variables from .vars
    namesFvars, infileColumnsFvars, filePathsFvars = parse_expandvars_fvarsfile_(fileFvars, namesVars, valuesVars; dlmFvars=delimiterFvars, adapt_quotation=adapt_quotation, tagsExpand=tagsExpand);
  end

  # Read .protocol file (of 1 column ) and expand variables from .vars
  (flagVerbose && length(namesVars) > 0) && println("Expanding variables in protocol file using values from the --vars file.");
  arrProtExpVars, cmdRowsProt = parse_expandvars_protocol_(fileProtocol, namesVars, valuesVars, adapt_quotation=adapt_quotation);

  dictListArr = Dict(); dictCmdLineIdxs = Dict();
  if parsed_args["fvars"] != nothing
    println(string("Expanding variables from the --fvars file using values from the files listed in each row..."));
    dictListArr, dictCmdLineIdxs = parse_expandvars_listfiles_(filePathsFvars, namesVars, valuesVars, delimiterFvars; verbose=false, adapt_quotation=adapt_quotation, tagsExpand=tagsExpand);
    if length(keys(dictListArr)) != length(keys(dictCmdLineIdxs))
      error("Numbers of command rows (", length(keys(dictListArr)), ") and command row indices (", length(keys(dictCmdLineIdxs)), ") in list file (", filePathsFvars, ") do not match.")
    end
  end

  ## Create summary files
  # Use variable values from "list" files to create multiple summary file arrays from the single .protocol file array
  flagVerbose && println("Creating summary files...");
  arrArrExpFvars = [];
  if length(keys(dictListArr)) != 0 && length(keys(dictCmdLineIdxs)) != 0
    arrArrExpFvars = protocol_to_array(arrProtExpVars, cmdRowsProt, namesFvars, infileColumnsFvars, filePathsFvars, dictListArr, dictCmdLineIdxs; verbose=verbose, adapt_quotation=adapt_quotation);
  else
    push!(arrArrExpFvars, arrProtExpVars); # If there is no data from list files, simply proceed using the protocol with expanded varibles (if applicable)
  end
  # Generate list of summary file paths.
  summaryPaths = get_summary_names(arrArrExpFvars; tag="#JSUB<summary-name>", # if an entry with this tag is found in the protocol (arrArrExpFvars), the string following the tag will be used as the name
    longName=longName, # Otherwise the string passed to longName will be used as the basis of the summary file name
    prefix=summaryFilePrefix,
    suffix=".summary",
    timestamp=(
      parsed_args["timestamp"] ? get_timestamp_(nothing) : "";
    )
  );
  # Take an expanded protocol in the form of an array of arrays and produce a summary file for each entry
  outputSummaryPaths = create_summary_files_(arrArrExpFvars, summaryPaths; verbose=flagVerbose);
  println(string("Writing list of summary files to: ", pathSummariesList));
  writedlm(pathSummariesList, outputSummaryPaths);
end

## STAGE 2
if requiredStages[2] == '1'
  flagVerbose && println("\n - STAGE 2: Using summary files to generate LSF job files.");

  ## Read paths to summary files from list file
  summaryPaths2 = readdlm(pathSummariesList);

  # Note: file2arrayofarrays_ returns a tuple of file contents (in an array) and line number indices (in an array)
  summaryFilesData = map((x) -> file2arrayofarrays_(x, "#", cols=1, tagsExpand=tagsExpand), summaryPaths2 );

  flagVerbose && println("Importing bash functions from files...");
  arrDictCheckpoints = map((x) -> identify_checkpoints(x[1], checkpointsDict; tagCheckpoint="jcheck_"), summaryFilesData );
  arrBashFunctions = map((x) -> get_bash_functions(commonFunctions, x), arrDictCheckpoints);

  flagVerbose && println("Splitting summary file contents into separate jobs...");
  summaryArrDicts = map((x) -> split_summary(x[1]; tagSplit=tagsExpand["tagSplit"]), summaryFilesData);

  flagVerbose && println("Getting job file names from summary file basenames...");
  arrJobIDs = map((x) -> basename(remove_suffix(x, ".summary")) , summaryPaths2);

  # Get arguments for passing to create_jobs_from_summary_
  doJsubVersionControl=(get_argument(parsed_args, "no-version-control"; verbose=flagVerbose, optional=true, default=true));
  processTimestamp=(get_argument(parsed_args, "no-process-timestamp"; verbose=flagVerbose, optional=true, default=true));
  # (processTimestamp == false) && processTimestamp = "false"; # Convert to string as this will be written directly to the job file
  ## Write job files
  jobFilePathsArrays2 = map((summaryFilePath, dictSummaries, jobID) -> create_jobs_from_summary_(summaryFilePath, dictSummaries, commonFunctions, checkpointsDict; 
      jobFilePrefix=jobFilePrefix, jobID=jobID, jobDate=(
        parsed_args["timestamp"] ? get_timestamp_(nothing) : "";
      ),
      doJsubVersionControl=doJsubVersionControl,
      processTimestamp=processTimestamp,
      headerSuffix=commonHeaderSuffix, verbose=flagVerbose, bsubOptions=bsubOptions
    ),
    summaryPaths2, summaryArrDicts, arrJobIDs,
  );
  string2file_(pathJobsList, arrArr2string(jobFilePathsArrays2)) # Convert array of arrays into a single string
end

## STAGE 3
if requiredStages[3] == '1'
  flagVerbose && println("\n - STAGE 3: Submitting LSF jobs.");

  ## Call the job submission script or copy it to the jobs directory
  if parsed_args["portable"] == false
    SUPPRESS_WARNINGS ? arg2 = "suppress-warnings" : arg2 = "";
    flagVerbose && println("Submitting jobs to LSF queuing system using...");
    flagVerbose && println("bash $pathSubmissionScript $pathJobsList $arg2");
    subRun = "";
    try
      run(`bash $pathSubmissionScript $pathJobsList $arg2`);
    catch
      println(subRun);
    end
  else
    flagVerbose && println(string("Writing a copy of the submission script and functions file to the job file directory: ", dirJobs));
    cp(pathSubmissionScript, string(dirJobs, "/", basename(pathSubmissionScript)));
    cp(pathSubmissionFunctions, string(dirJobs, "/", basename(pathSubmissionFunctions)));
    flagVerbose && println(string("The jobs can be submitted to the queuing system by running the shell script, for example: ", ));
  end

  ## Zip jobs directory if requested
  if parsed_args["zip-jobs"] == true
    flagVerbose && println("Zipping jobs directory: ", dirJobs);
    dirJobsZip = string(dirJobs, ".tar.gz");
    flagVerbose && println("             into file: ", dirJobsZip);
    flagVerbose ? zipVerbose = " -v " : zipVerbose = ""
    subZip = "";
    try
      subZip = run(`tar -z -c -f $zipVerbose $dirJobsZip $dirJobs`);
    catch
      println(subZip);
    end
  end

  flagVerbose && println("");
end

# end
# main(ARGS)

# Report if there were any suppressed warnings
if num_suppressed[1] > 0
  println("Suppressed ", num_suppressed[1], " warnings.");
end
########################
# EOF

